<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>cesarsalgado.com</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Le styles -->
    <link href="/css/bootstrap.css" rel="stylesheet">
    <link href="/css/bootstrap-responsive.css" rel="stylesheet">
    <link href="/css/style.css" rel="stylesheet">
    <link href="/js/google-code-prettify/prettify.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="/js/html5shiv.js"></script>
    <![endif]-->

    <!-- Le fav and touch icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="/ico/apple-touch-icon-114-precomposed.png">
      <link rel="apple-touch-icon-precomposed" sizes="72x72" href="/ico/apple-touch-icon-72-precomposed.png">
                    <link rel="apple-touch-icon-precomposed" href="/ico/apple-touch-icon-57-precomposed.png">
                                   <link rel="shortcut icon" href="/ico/favicon.png">


        
  </head>

  <body data-spy="scroll" data-target=".bs-docs-sidebar">


    
<!-- Navbar
================================================== -->

<div class="navbar navbar-inverse navbar-fixed-top">
  <div class="navbar-inner">
    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span10">
          <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>

          <!-- Button to homepage -->
          <a class="brand" href="/">cesarsalgado.com</a>

          <div class="nav-collapse collapse">
            <ul class="nav">

              <!-- Home -->
              <li class="" >
                <a href="/">Home</a>
              </li>

              <!-- Blog -->
              <li class="active" >
                <a href="/blog">Blog</a>
              </li>

              <!-- Curriculum -->
              <li class="" >
                <a href="/curriculum">Curriculum</a>
              </li>

              <!-- Academic -->
              <li class="" >
                <a href="/academic">Academic</a>
              </li>

              <!-- About -->
              <!--
              <li class="" >
                <a href="/about">Bio</a>
              </li>
              -->


              <!-- Contact -->
              <li class="" >
                <a href="/contact">Contact</a>
              </li>

              <!-- Apps -->
    <!--           
              <li class="" >
                <a href="/apps">Apps</a>
              </li>
     -->
    <!--           
              <li class="" >
                <a href="/more">More</a>
              </li>
     -->        
            </ul>
          </div>
        </div>
        <div class="span2">
          <div class="nav-collapse collapse">
            <ul class="nav">

              <!-- English -->

              <!-- Portuguese -->
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>


<div id="no-sidenav-container" class="container">

  <section>
    <a href="/blog">Go back to list of posts</a>
    <div class="page-header">
      <h1>IPython Notes on Understanding Deep Image Representations By Inverting Them</h1>
    </div>

    <h4><time>Nov 23, 2015</time></h4>
    <br>
    <div id="post_content">
      <p><strong>Paper title</strong>: Understanding Deep Image Representations by Inverting Them</p>

<p><strong>Authors</strong>: Aravindh Mahendran, Andrea Vedaldi</p>

<p><strong>Link</strong>: <a href="http://arxiv.org/abs/1412.0035">http://arxiv.org/abs/1412.0035</a></p>

<p><sub><strong>Warning</strong>: The code in this post is just for illustrative purposes. It isn&rsquo;t runnable.</sub></p>

<h2>Summary</h2>

<p>This paper tries to reconstruct an image from its representation as a way of visualizing its information. The proposed method is applied to representations obtained from CNN, HOG or DSIFT. It tries to find a reconstructed image xr by minimizing the Euclidean distance between the representation of xr and that of the original image. A regularizer is also added to the loss to be minimized to produce more natural looking images. The paper uses SGD with momentum to perform the minimization. Let start focusing on CNNs.</p>
<div class="highlight python"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7</pre></td><td class="code"><pre><span class="c"># Let's suppose we are using AlexNet and the representation is obtained in its 3rd fully connected (fc) layer.</span>
<span class="c"># h is the representation of image x given by the activations of the 3rd fc layer of the CNN.</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">cnn_fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c"># The paper wants to find one image xr such that cnn_fc3(xr) is close to h </span>
<span class="n">xr</span> <span class="o">=</span> <span class="n">reconstruct</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">cnn_fc3</span><span class="p">)</span>
<span class="n">hr</span> <span class="o">=</span> <span class="n">cnn_fc3</span><span class="p">(</span><span class="n">xr</span><span class="p">)</span>
<span class="nb">sum</span><span class="p">((</span><span class="n">hr</span><span class="o">-</span><span class="n">h</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">epsilon</span> <span class="o">==</span> <span class="bp">True</span> <span class="c"># means that the two hs are close.</span>
</pre></td></tr></tbody></table>
</div>

<p>One of the desired properties of CNNs trained for object recognition is that they are invariant to many transformations of the input. That also means that they are not invertible functions. So there are many input images that will produce the same representation.</p>
<div class="highlight python"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre><span class="c"># There are many pairs xi and xj such that:</span>
<span class="n">np</span><span class="o">.</span><span class="nb">all</span><span class="p">(</span><span class="n">cnn_fc3</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span> <span class="o">==</span> <span class="n">cnn_fc3</span><span class="p">(</span><span class="n">xj</span><span class="p">))</span> <span class="o">==</span> <span class="bp">True</span>
</pre></td></tr></tbody></table>
</div>

<p>Some of these images will probably not even look natural as the following paper on adversarial examples show: <a href="http://arxiv.org/abs/1412.1897">Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images</a></p>

<p>But the current paper wants only to find natural looking images so it incorporates an image &ldquo;prior&rdquo; to the reconstruction method. The way it incorporates the prior is the main novelty of the paper.</p>

<p>The problem of finding the reconstruction is posed as an optimization problem of trying to minimize the Euclidian distance between hr and h:</p>
<div class="highlight python"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre><span class="n">xr</span> <span class="o">=</span> <span class="n">argmin</span><span class="p">(</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span> <span class="p">((</span><span class="n">cnn_fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="n">h</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="p">)</span> <span class="p">)</span>
</pre></td></tr></tbody></table>
</div>

<p>But we also need to restrict the possible xr to look natural. So the paper adds also a &ldquo;prior&rdquo; as a regularizer to the loss equation:</p>
<div class="highlight python"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre><span class="n">xr</span> <span class="o">=</span> <span class="n">argmin</span><span class="p">(</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span> <span class="p">((</span><span class="n">cnn_fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="n">h</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">regularizer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">)</span> <span class="p">)</span>
</pre></td></tr></tbody></table>
</div>

<p>Actually, the paper uses an equation a bit different from the above to make the guessing of the initial hyper-parameter easier. See section <strong>Balancing the different terms</strong> for more information.</p>

<p>The regularizer term is defined as the sum of two sub-terms: </p>
<div class="highlight python"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18</pre></td><td class="code"><pre><span class="c"># this regularizer is one of the main paper's contribution.</span>
<span class="k">def</span> <span class="nf">regularizer</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">mult1</span> <span class="o">=</span> <span class="mf">2.6</span><span class="o">*</span><span class="mf">1e8</span>
    <span class="n">mult2</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="k">return</span> <span class="n">mult1</span><span class="o">*</span><span class="n">six_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">mult2</span><span class="o">*</span><span class="n">total_variation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">six_norm</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">6</span><span class="p">)</span>

<span class="c"># this is the finite-difference approx. of the total variation</span>
<span class="k">def</span> <span class="nf">total_variation</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">result</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="c"># suppose x is properly zero padded.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="p">(</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">beta</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></td></tr></tbody></table>
</div>

<p>The optimization problem is then solved by using SGD with momentum as all the parts of the loss function are differentiable on x (including off course cnn_fc3).</p>

<p>To visualize the representation of HOG and DSIFT the authors first build these methods using the CNN layers so it becomes easy to differentiate on the input. The algorithm then proceeds as before.</p>

<h2>Experiments</h2>

<p>The authors tried to reconstruct the images from other layers of the CNN too. The image below, that was extracted from the paper, shows the reconstruction of an image from the representation of different layers of the used CNN.</p>

<p><img alt="notebook_image" src="/posts/notebooks/imgs/understanding_deep_image_representations_by_inverting_them__figure_6.png" /></p>

<p>It can be seen that the first layers preserve almost all information of the image and the last layers loses information about the location of the object, for instance, but retain information about some discriminative features of the objects.</p>

<h2>Conclusion</h2>

<p>I hope papers like this one ends the myth that Neural Nets are black box algorithms. There are many works that try to visualize and understand what is happening inside them CNNs. Below I list some of them:</p>

<ul>
<li><p><a href="http://arxiv.org/abs/1311.2901">Visualizing and Understanding Convolutional Networks</a></p></li>
<li><p><a href="http://arxiv.org/abs/1312.6034">Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</a></p></li>
<li><p><a href="http://yosinski.com/media/papers/Yosinski__2015__ICML_DL__Understanding_Neural_Networks_Through_Deep_Visualization__.pdf">Understanding Neural Networks Through Deep Visualization</a></p></li>
</ul>

<p>The last paper from above has also made available their code: <a href="https://github.com/yosinski/deep-visualization-toolbox">https://github.com/yosinski/deep-visualization-toolbox</a></p>

<p>I read this paper, because I started reading <a href="http://arxiv.org/abs/1508.06576">A Neural Algorithm of Artistic Style</a> and I thought I needed first to read some of its references. So probably my next notes will be about the above paper and the following former work by the same authors: <a href="arxiv.org/abs/1505.07376">Texture Synthesis Using Convolutional Neural Networks</a></p>

<h4>The Fine Print</h4>

<p><sub>These notes are similar in spirit to <a href="https://twitter.com/hugo_larochelle">https://twitter.com/hugo_larochelle</a> notes that he announces in his Twitter. The only difference is that from time to time I will also write notes in Jupyter Notebook and insert some small code samples to understand better the concepts exposed in the papers. The code is not meant to reproduce the paper and sometimes may not even be runnable as I pretend not to spend too much time on every paper I read. Sometimes I may wish to dig deeper into a paper and try to reproduce the results, but then I will tag the blog post in a different section of my blog.</sub></p>

<p><sub><strong>Post generated from the following IPython Notebook</strong>: <a href="https://github.com/cesarsalgado/cesarsalgado.github.io/blob/master/middleman/source/posts/notebooks/2015-11-23-ipython_notes_on_understanding_deep_image_representations_by_inverting_them-en.ipynb">https://github.com/cesarsalgado/cesarsalgado.github.io/blob/master/middleman/source/posts/notebooks/2015-11-23-ipython_notes_on_understanding_deep_image_representations_by_inverting_them-en.ipynb</a></sub></p>

    </div>
    <hr></hr>
    <a href="/blog">Go back to list of posts</a>
      <hr></hr>
      <div id="disqus_thread"></div>
        <script type="text/javascript">
          /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
          var disqus_shortname = "cesarsalgadoen"; // Required - Replace '<example>' with your forum shortname
          var disqus_title = 'IPython Notes on Understanding Deep Image Representations By Inverting Them';
          var disqus_url = 'http://cesarsalgado.com/ipython_notes_on_understanding_deep_image_representations_by_inverting_them/';

          /* * * DON'T EDIT BELOW THIS LINE * * */
          (function() {
              var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
              dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
              (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
          })();
        </script>
      <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
      <hr></hr>
      <a href="/blog">Go back to list of posts</a>
  </section>


</div>




    <!-- Footer
    ================================================== -->
    <footer class="footer">
      <div class="container">
        <p>Hosted on <a href='http://pages.github.com'>Github Pages</a> and powered by <a href='http://middlemanapp.com'>Middleman</a>.</p>
        <p>This site used as a starting point the <a href='http://getbootstrap.com/2.3.2/'>Bootstrap 2.3.2 Docs site</a>.</p>
        <p>This work is licensed under <a href="http://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>.</p>
        <ul class="footer-links">
          <li><a href='http://www.linkedin.com/pub/cesar-salgado/13/641/505'>Linkedin</a></li>
          <li class="muted">&middot;</li>
          <li><a href='https://plus.google.com/100294158210704939412'>Google+</a></li>
          <li class="muted">&middot;</li>
          <li><a href='http://www.facebook.com/cesar.salgado.332'>Facebook</a></li>
          <li class="muted">&middot;</li>
          <li><a href='https://twitter.com/cesarsvs'>Twitter</a></li>
          <li class="muted">&middot;</li>
          <li><a href="https://www.quora.com/Cesar-Salgado-1">Quora</a></li>
          <li class="muted">&middot;</li>
          <li><a href='https://github.com/cesarsalgado'>Github</a></li>
          <!--<li class="muted">&middot;</li>
          <li><a href='http://stackoverflow.com/users/604964/cesarsalgado'>Stack Overflow</a></li>-->
          <li class="muted">&middot;</li>
          <li><a href='https://www.coursera.org/user/i/79af8cc4af779e350b4a6d2c09cb09a7'>Coursera</a></li>
          <li class="muted">&middot;</li>
          <li><a href='https://www.kaggle.com/users/118042/cesar'>Kaggle</a></li>
        </ul>
      </div>
    </footer>



    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="/js/jquery.js"></script>
    <script src="/js/bootstrap-transition.js"></script>
    <script src="/js/bootstrap-alert.js"></script>
    <script src="/js/bootstrap-modal.js"></script>
    <script src="/js/bootstrap-dropdown.js"></script>
    <script src="/js/bootstrap-scrollspy.js"></script>
    <script src="/js/bootstrap-tab.js"></script>
    <script src="/js/bootstrap-tooltip.js"></script>
    <script src="/js/bootstrap-popover.js"></script>
    <script src="/js/bootstrap-button.js"></script>
    <script src="/js/bootstrap-collapse.js"></script>
    <script src="/js/bootstrap-carousel.js"></script>
    <script src="/js/bootstrap-typeahead.js"></script>
    <script src="/js/bootstrap-affix.js"></script>

    <script src="/js/holder/holder.js"></script>
    <script src="/js/google-code-prettify/prettify.js"></script>

    <script src="/js/application.js"></script>


    <!-- Analytics
    ================================================== -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-66558584-1', 'auto');
      ga('send', 'pageview');
    </script>

  </body>
</html>
